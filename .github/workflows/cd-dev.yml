name: Deploy to Development

on:
  push:
    branches: [ develop ]
  workflow_dispatch:
    inputs:
      force_deploy:
        description: 'Force deployment even if tests fail'
        required: false
        default: false
        type: boolean

env:
  ENVIRONMENT: dev
  AZURE_RESOURCE_GROUP: rg-hiscox-etl-dev
  TERRAFORM_VERSION: 1.5.0

jobs:
  deploy-infrastructure:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    environment: development
    outputs:
      databricks_url: ${{ steps.terraform-outputs.outputs.databricks_url }}
      storage_account: ${{ steps.terraform-outputs.outputs.storage_account }}
      key_vault_uri: ${{ steps.terraform-outputs.outputs.key_vault_uri }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS_DEV }}
          
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
          terraform_wrapper: false
          
      - name: Cache Terraform
        uses: actions/cache@v3
        with:
          path: |
            terraform/.terraform
            terraform/.terraform.lock.hcl
          key: terraform-dev-${{ hashFiles('terraform/**/*.tf') }}
          
      - name: Terraform Init
        run: |
          cd terraform/environments/dev
          terraform init
          
      - name: Terraform Plan
        run: |
          cd terraform/environments/dev
          terraform plan -out=tfplan -detailed-exitcode
        continue-on-error: true
        
      - name: Terraform Apply
        run: |
          cd terraform/environments/dev
          terraform apply -auto-approve tfplan
          
      - name: Capture Terraform Outputs
        id: terraform-outputs
        run: |
          cd terraform/environments/dev
          echo "databricks_url=$(terraform output -raw databricks_workspace_url)" >> $GITHUB_OUTPUT
          echo "storage_account=$(terraform output -raw storage_account_name)" >> $GITHUB_OUTPUT
          echo "key_vault_uri=$(terraform output -raw key_vault_uri)" >> $GITHUB_OUTPUT

  build-and-push:
    name: Build and Push Images
    runs-on: ubuntu-latest
    needs: deploy-infrastructure
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS_DEV }}
          
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
        
      - name: Login to Azure Container Registry
        run: |
          az acr login --name acrhiscoxetldev001am
          
      - name: Build and push ingestion image
        uses: docker/build-push-action@v4
        with:
          context: .
          file: ./docker/ingestion.Dockerfile
          push: true
          tags: |
            acrhiscoxetldev001am.azurecr.io/etl-ingestion:${{ github.sha }}
            acrhiscoxetldev001am.azurecr.io/etl-ingestion:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max
          
      - name: Build and push transformation image
        uses: docker/build-push-action@v4
        with:
          context: .
          file: ./docker/transformation.Dockerfile
          push: true
          tags: |
            acrhiscoxetldev001am.azurecr.io/etl-transformation:${{ github.sha }}
            acrhiscoxetldev001am.azurecr.io/etl-transformation:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy-application:
    name: Deploy Application
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure, build-and-push]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-minimal.txt
          
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS_DEV }}
          
      - name: Update environment variables
        run: |
          echo "DATABRICKS_HOST=${{ needs.deploy-infrastructure.outputs.databricks_url }}" >> .env
          echo "AZURE_STORAGE_ACCOUNT_NAME=${{ needs.deploy-infrastructure.outputs.storage_account }}" >> .env
          echo "AZURE_KEY_VAULT_URI=${{ needs.deploy-infrastructure.outputs.key_vault_uri }}" >> .env
          
      - name: Deploy to Databricks
        run: |
          # Install Databricks CLI
          pip install databricks-cli
          
          # Configure Databricks CLI (you'll need to set DATABRICKS_TOKEN in secrets)
          echo "${{ secrets.DATABRICKS_TOKEN_DEV }}" | databricks configure --token --host ${{ needs.deploy-infrastructure.outputs.databricks_url }}
          
          # Upload notebooks and scripts
          databricks workspace import-dir scripts/ /Repos/etl-hiscox/scripts --overwrite
          
      - name: Run initial data setup
        run: |
          python scripts/setup/create_initial_tables.py --environment dev
        env:
          AZURE_STORAGE_ACCOUNT_NAME: ${{ needs.deploy-infrastructure.outputs.storage_account }}
          AZURE_KEY_VAULT_URI: ${{ needs.deploy-infrastructure.outputs.key_vault_uri }}

  run-tests:
    name: Run End-to-End Tests
    runs-on: ubuntu-latest
    needs: deploy-application
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-minimal.txt
          pip install pytest
          
      - name: Run data quality tests
        run: |
          pytest tests/data_quality/ -v --env=dev
        env:
          DATABRICKS_HOST: ${{ needs.deploy-infrastructure.outputs.databricks_url }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN_DEV }}
          
      - name: Run integration tests
        run: |
          pytest tests/integration/ -v --env=dev
        env:
          AZURE_STORAGE_ACCOUNT_NAME: ${{ needs.deploy-infrastructure.outputs.storage_account }}
          AZURE_KEY_VAULT_URI: ${{ needs.deploy-infrastructure.outputs.key_vault_uri }}

  notify-deployment:
    name: Notify Deployment Status
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure, build-and-push, deploy-application, run-tests]
    if: always()
    steps:
      - name: Notify Slack
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#data-engineering'
          text: |
            ðŸš€ Development deployment ${{ job.status }}
            Environment: Development
            Commit: ${{ github.sha }}
            Actor: ${{ github.actor }}
            Databricks URL: ${{ needs.deploy-infrastructure.outputs.databricks_url }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        if: always()
